llm:
  temperature: 0.1
  max_tokens: 1500

prompts:
  test_case_explainer: prompts/test_case_explainer.txt
  project_summary: prompts/project_summary.txt
